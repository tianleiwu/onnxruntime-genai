#!/usr/bin/env python3
import pandas as pd
import numpy as np
import textwrap
import argparse

def analyze_and_generate_code(csv_file):
    """
    Reads the benchmark summary CSV, analyzes it to find the k-thresholds
    for selection sort, and prints a C++ code snippet with the results.
    """
    try:
        df = pd.read_csv(csv_file)
    except FileNotFoundError:
        print(f"Error: '{csv_file}' not found.")
        print("Please run the C++ benchmark first to generate the summary file.")
        return

    # Drop rows where best_algorithm is not determined
    df.dropna(subset=['best_algorithm'], inplace=True)

    # Get the unique batch and vocab sizes from the data, ensuring they are sorted
    batch_sizes = sorted(df['batch_size'].unique())
    vocab_sizes = sorted(df['vocab_size'].unique())

    if not batch_sizes or not vocab_sizes:
        print("Error: No valid data found in CSV file.")
        return

    # Initialize the threshold matrix with the default value of 1
    thresholds = np.ones((len(batch_sizes), len(vocab_sizes)), dtype=int)

    # Calculate thresholds for each (batch_size, vocab_size) pair
    for i, bs in enumerate(batch_sizes):
        for j, vs in enumerate(vocab_sizes):
            # Filter for the current configuration where selection sort was the best
            subset = df[
                (df['batch_size'] == bs) &
                (df['vocab_size'] == vs) &
                (df['best_algorithm'] == 'SELECTION_SORT')
            ]

            # If there are any such results, find the maximum k
            if not subset.empty:
                max_k = subset['k'].max()
                thresholds[i, j] = int(max_k)

    # --- Format the output as a C++ code snippet ---
    print("// --- Generated by topk_benchmark_analysis.py ---")

    # Print batch sizes vector
    print("static const std::vector<int> sampled_batch_sizes = {", end="")
    print(*batch_sizes, sep=", ", end="};\n")

    # Print vocab sizes vector, wrapped for readability
    vocab_str = ", ".join(map(str, vocab_sizes))
    wrapped_vocab = textwrap.fill(vocab_str, width=80, initial_indent='    ', subsequent_indent='    ')
    print("static const std::vector<int> sampled_vocab_sizes = {")
    print(wrapped_vocab)
    print("};")
    print(f"const int num_vocab_sizes = {len(vocab_sizes)};\n")

    # Print the flattened 2D array of k-thresholds
    print("// A flattened 2D array of k-thresholds, with shape ({}, {}).".format(len(batch_sizes), len(vocab_sizes)))
    print("static const std::vector<int> benchmark_data = {")
    for i, bs in enumerate(batch_sizes):
        print(f"    // Batch Size {bs}")
        row_str = ", ".join(map(str, thresholds[i, :]))
        print(f"    {row_str},")
    print("};")
    print("// --- End of generated code ---")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Analyze Top-K benchmark results and generate C++ code."
    )
    parser.add_argument(
        "csv_file",
        nargs="?",
        default="build/Linux/Release/test/topk_benchmark_summary.csv",
        help="Path to the benchmark summary CSV file",
    )
    args = parser.parse_args()
    analyze_and_generate_code(args.csv_file)

